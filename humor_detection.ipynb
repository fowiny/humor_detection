{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "humor_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamdsc/humor_detection/blob/master/humor_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UnjCSMWA_bod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Humor Detection in One-liners"
      ]
    },
    {
      "metadata": {
        "id": "6UQVLvMr3_8S",
        "colab_type": "code",
        "outputId": "0cda9a82-de6a-4be3-f589-6d0117038e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "## cloning the repo\n",
        "!git clone https://github.com/iamdsc/humor_detection.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'humor_detection'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/13)   \u001b[K\rremote: Counting objects:  15% (2/13)   \u001b[K\rremote: Counting objects:  23% (3/13)   \u001b[K\rremote: Counting objects:  30% (4/13)   \u001b[K\rremote: Counting objects:  38% (5/13)   \u001b[K\rremote: Counting objects:  46% (6/13)   \u001b[K\rremote: Counting objects:  53% (7/13)   \u001b[K\rremote: Counting objects:  61% (8/13)   \u001b[K\rremote: Counting objects:  69% (9/13)   \u001b[K\rremote: Counting objects:  76% (10/13)   \u001b[K\rremote: Counting objects:  84% (11/13)   \u001b[K\rremote: Counting objects:  92% (12/13)   \u001b[K\rremote: Counting objects: 100% (13/13)   \u001b[K\rremote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 13 (delta 2), reused 9 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (13/13), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G88MdzlpA1fC",
        "colab_type": "code",
        "outputId": "9f0adcde-ef26-49d7-bef4-c3c67093f032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "%cd humor_detection/datasets/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/humor_detection/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SeKV32tTB8pE",
        "colab_type": "code",
        "outputId": "36512c46-a891-443b-f38f-03888eb2932d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "humorous_oneliners.pickle      proverbs.pickle\t\t wiki_sentences.pickle\n",
            "oneliners_incl_doubles.pickle  reuters_headlines.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "byjqlL3jCOkj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "humour = pd.read_pickle('humorous_oneliners.pickle')\n",
        "proverb = pd.read_pickle('proverbs.pickle')\n",
        "wiki = pd.read_pickle('wiki_sentences.pickle')\n",
        "long_humour = pd.read_pickle('oneliners_incl_doubles.pickle')\n",
        "reuters = pd.read_pickle('reuters_headlines.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eFBE0uB5Lbmn",
        "colab_type": "code",
        "outputId": "56382898-1271-416f-e307-11208db2dacc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(humour), len(proverb), len(wiki), len(reuters))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5251 1019 5251 5243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ke4Ll6YFP-a-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# building dataframe from the data\n",
        "# giving humourous sentence positive class and rest negative class\n",
        "humour_record = [(sent, 1) for sent in humour]\n",
        "proverb_record = [(sent, 0) for sent in proverb]\n",
        "wiki_record = [(sent, 0) for sent in wiki]\n",
        "reuter_record = [(sent, 0) for sent in reuters]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxOgamn5RTtg",
        "colab_type": "code",
        "outputId": "edb75f15-5cb6-4412-c900-105642e155dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "pos_record = humour_record\n",
        "neg_record = proverb_record + wiki_record + reuter_record\n",
        "columns = ['sentence', 'class']\n",
        "\n",
        "# Randomly picking len(pos_records) records from negative class\n",
        "random.shuffle(neg_record)\n",
        "neg_record = neg_record[:len(pos_record)]\n",
        "\n",
        "# Build the dataframe\n",
        "df_record = pos_record + neg_record \n",
        "df = pd.DataFrame(df_record, columns=columns)\n",
        "\n",
        "# shuffle the dataframe and reset the index\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "print(df.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                            sentence  class\n",
            "0                       A Black Hen Lays A White Egg      0\n",
            "1  At what point does a Lamb become a Sheep? When...      1\n",
            "2     U.S. jobless claims fall more than expected:        0\n",
            "3  Periodically he would organize a new band and ...      0\n",
            "4  Need experience for job. Need job for experience.      1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PuV4QJJzSj9m",
        "colab_type": "code",
        "outputId": "28f112ad-0fed-4188-be4b-2cadb4498644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "df['class'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5251\n",
              "0    5251\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "iNzu8-u4Dt0h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating word vectors\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "text=[]\n",
        "for sentence,_ in df_record:\n",
        "  sent_word_list = [word for word in sentence.lower().split()]\n",
        "  text.append(sent_word_list)\n",
        "\n",
        "w2v = Word2Vec(text, min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_IQGY0_WZ7VI",
        "colab_type": "code",
        "outputId": "36cc55c2-e5e4-4baf-e049-882381d49d5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "# building list of sentence vectors\n",
        "vect_record=[]\n",
        "for i in range(len(df['sentence'])):\n",
        "  sent = df['sentence'][i]\n",
        "  if len(sent)!=0:\n",
        "    sent_vect = sum([w2v[w] for w in sent.lower().split()])/(len(sent.split())+0.001)\n",
        "  else:  \n",
        "    sent_vect = np.zeros((100,))\n",
        "  vect_record.append(sent_vect) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "U6fQDPuIgSbA",
        "colab_type": "code",
        "outputId": "f311bb33-939b-44a6-c327-79232c9c4e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(vect_record, columns=range(100))\n",
        "print(X.head())\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         0         1         2         3         4         5         6   \\\n",
            "0 -0.299317  0.261278  0.500360  0.514710  0.133264  0.317683 -0.058355   \n",
            "1 -0.418768  0.344506  0.702678  0.761039  0.210620  0.422604 -0.046371   \n",
            "2 -0.252735  0.216322  0.406221  0.424718  0.103921  0.253117 -0.037577   \n",
            "3 -0.381051  0.328394  0.609629  0.633020  0.158734  0.391795 -0.073301   \n",
            "4 -0.259524  0.233595  0.414892  0.419551  0.096390  0.273825 -0.052584   \n",
            "\n",
            "         7         8         9     ...           90        91        92  \\\n",
            "0 -0.000443  0.297339 -0.935085    ...    -0.203419 -0.241452 -0.787392   \n",
            "1  0.009775  0.351279 -1.235259    ...    -0.336546 -0.246760 -1.086021   \n",
            "2 -0.002454  0.238438 -0.757676    ...    -0.170742 -0.188063 -0.645034   \n",
            "3  0.000465  0.380359 -1.165326    ...    -0.241877 -0.314932 -0.983472   \n",
            "4 -0.007803  0.281696 -0.810582    ...    -0.149636 -0.245752 -0.679057   \n",
            "\n",
            "         93        94        95        96        97        98        99  \n",
            "0  0.557964  0.159228 -0.048006 -0.507913  0.153861 -0.001579 -0.135559  \n",
            "1  0.754090  0.233646 -0.050419 -0.703415  0.240152  0.006094 -0.272936  \n",
            "2  0.454075  0.132222 -0.032281 -0.411887  0.127283 -0.008979 -0.129831  \n",
            "3  0.697760  0.197396 -0.055102 -0.623224  0.188471 -0.007578 -0.169354  \n",
            "4  0.481860  0.139870 -0.042659 -0.422349  0.122325 -0.013692 -0.102694  \n",
            "\n",
            "[5 rows x 100 columns]\n",
            "(10502, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wy84zVMsbTfu",
        "colab_type": "code",
        "outputId": "2e6c126c-d914-43c8-f26c-55182c7e1e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "y = df['class']\n",
        "print(type(y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7HXFjdR38pFK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Performaing train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KIte5x6C9VsB",
        "colab_type": "code",
        "outputId": "a51eec9e-fcb5-4516-8755-4edae3107864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print('Training Data: ', X_train.shape, y_train.shape)\n",
        "print('Test Data: ', X_test.shape, y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data:  (8401, 100) (8401,)\n",
            "Test Data:  (2101, 100) (2101,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qRJLse1v9n5K",
        "colab_type": "code",
        "outputId": "3deef819-626d-4439-fd7a-e7521f920186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# fit the SVM model with linear Kernel\n",
        "svm = SVC(kernel='linear', random_state=1, C=1.0)\n",
        "svm.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "  kernel='linear', max_iter=-1, probability=False, random_state=1,\n",
              "  shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Ao_yt6XSAidX",
        "colab_type": "code",
        "outputId": "40e5c527-7c03-43c3-cad3-d9f99245fd98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# performing prediction in test samples\n",
        "y_pred = svm.predict(X_test)\n",
        "print(y_pred[:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rDC1kscSBi1O",
        "colab_type": "code",
        "outputId": "660996c4-4476-4d52-9ae0-ada298777438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Calculating Classification Accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Test Accuracy Score: ',accuracy_score(y_pred, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy Score:  0.817705854355069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-tUfXBz2CC2a",
        "colab_type": "code",
        "outputId": "f8dfbe86-967c-46e0-a84a-b0c650e7b930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Calculating Cross Validation Accuracy\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "scores = cross_val_score(estimator=svm, X=X_train, y=y_train, cv=10, n_jobs=-1)\n",
        "print('CV accuracy: %.3f +/- %.3f'%(np.mean(scores),np.std(scores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CV accuracy: 0.809 +/- 0.011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fcddQIk3IYFm",
        "colab_type": "code",
        "outputId": "b8036bf6-8887-4c68-dc74-6d12552367d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "cell_type": "code",
      "source": [
        "# Using Logistic Regression Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(C=100.0, random_state=1)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# performing prediction on test samples\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "print('Test Accuracy score: ', accuracy_score(y_pred, y_test))\n",
        "\n",
        "scores = cross_val_score(estimator=lr, X=X_train, y=y_train, cv=10, n_jobs=-1)\n",
        "print('CV accuracy: %.3f +/- %.3f'%(np.mean(scores),np.std(scores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy score:  0.8810090433127082\n",
            "CV accuracy: 0.872 +/- 0.007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "czTvj-4A4Fvs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}